{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moGj2h9L8oKp"
      },
      "source": [
        "# Setup environment\n",
        "\n",
        "In Google Colab we need to roll back to the previous runtime 2025.07 - [see here](https://research.google.com/colaboratory/runtime-version-faq.html).\n",
        "\n",
        "Click \"Runtime\" → \"Change runtime type\" → \"Runtime version\" → \"2025.07\"\n",
        "\n",
        "Now we install some necessary libraries, including:\n",
        "- downgrade `tensorflow` to 2.14.0, the last version compatible with QKeras\n",
        "- `qkeras` - the quantization aware training library\n",
        "- `hls4ml` - the NN to FPGA library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ofDOUAq88oKr",
        "outputId": "20f39158-957a-4c9b-b8df-d45a7f9cbe5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.14.0\n",
            "  Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting qkeras\n",
            "  Downloading QKeras-0.9.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hls4ml\n",
            "  Downloading hls4ml-1.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.14.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (18.1.1)\n",
            "Collecting ml-dtypes==0.2.0 (from tensorflow==2.14.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.14.0)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (4.14.1)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.14.0)\n",
            "  Downloading wrapt-1.14.2-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.73.1)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.0)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from qkeras) (1.15.3)\n",
            "Collecting pyparser (from qkeras)\n",
            "  Downloading pyparser-1.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-model-optimization>=0.2.1 (from qkeras)\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from qkeras) (3.5)\n",
            "Collecting keras-tuner>=1.0.1 (from qkeras)\n",
            "  Downloading keras_tuner-1.4.8-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from qkeras) (1.6.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.11/dist-packages (from qkeras) (4.67.1)\n",
            "Collecting pydigitalwavetools==1.1 (from hls4ml)\n",
            "  Downloading pyDigitalWaveTools-1.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from hls4ml) (6.0.2)\n",
            "Collecting quantizers (from hls4ml)\n",
            "  Downloading quantizers-1.2.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.45.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner>=1.0.1->qkeras) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner>=1.0.1->qkeras)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.23.1->qkeras) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.23.1->qkeras) (3.6.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.1.3)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization>=0.2.1->qkeras) (0.1.9)\n",
            "Collecting numpy>=1.23.5 (from tensorflow==2.14.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parse==1.6.5 (from pyparser->qkeras)\n",
            "  Downloading parse-1.6.5.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization>=0.2.1->qkeras) (25.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner>=1.0.1->qkeras) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner>=1.0.1->qkeras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner>=1.0.1->qkeras) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner>=1.0.1->qkeras) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.3.1)\n",
            "Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading QKeras-0.9.0-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hls4ml-1.2.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyDigitalWaveTools-1.1-py3-none-any.whl (13 kB)\n",
            "Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_tuner-1.4.8-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m125.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.2-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading quantizers-1.2.2-py3-none-any.whl (15 kB)\n",
            "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: pyparser, parse\n",
            "  Building wheel for pyparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyparser: filename=pyparser-1.0-py3-none-any.whl size=4913 sha256=3f68cea0b196c796912d95d67ed754e3844446a77c857b6b35e7a551707a4e62\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/48/69/eebe8cde4e13253d3c40be9bc8a9fae185922324be84233f7f\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.6.5-py3-none-any.whl size=18155 sha256=25be19855d6ffda0f07b809be93fca742d3a9a1571b7891e8b6658b5256ec650\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/e6/a0/9d6031f45532f6cea3b5f1d66417d0a0f842c42da1f076281c\n",
            "Successfully built pyparser parse\n",
            "Installing collected packages: pydigitalwavetools, parse, kt-legacy, wrapt, tensorflow-estimator, quantizers, pyparser, protobuf, numpy, keras, ml-dtypes, keras-tuner, tensorflow-model-optimization, hls4ml, google-auth-oauthlib, tensorboard, qkeras, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.14.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-1.0.0 hls4ml-1.2.0 keras-2.14.0 keras-tuner-1.4.8 kt-legacy-1.0.5 ml-dtypes-0.2.0 numpy-1.26.4 parse-1.6.5 protobuf-4.25.8 pydigitalwavetools-1.1 pyparser-1.0 qkeras-0.9.0 quantizers-1.2.2 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-model-optimization-0.8.0 wrapt-1.14.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "b8d94757579f4ed7847738c9354c895e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflow==2.14.0 qkeras hls4ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L01zVr7W8oKr",
        "outputId": "4733ed79-f6d3-43f1-f83c-57b25ffae63a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'hls4ml-tutorial'...\n",
            "Updating files:  16% (110/671)\rUpdating files:  17% (115/671)\rUpdating files:  18% (121/671)\rUpdating files:  19% (128/671)\rUpdating files:  19% (134/671)\rUpdating files:  20% (135/671)\rUpdating files:  21% (141/671)\rUpdating files:  22% (148/671)\rUpdating files:  23% (155/671)\rUpdating files:  24% (162/671)\rUpdating files:  25% (168/671)\rUpdating files:  26% (175/671)\rUpdating files:  27% (182/671)\rUpdating files:  28% (188/671)\rUpdating files:  29% (195/671)\rUpdating files:  30% (202/671)\rUpdating files:  31% (209/671)\rUpdating files:  32% (215/671)\rUpdating files:  33% (222/671)\rUpdating files:  34% (229/671)\rUpdating files:  35% (235/671)\rUpdating files:  36% (242/671)\rUpdating files:  37% (249/671)\rUpdating files:  38% (255/671)\rUpdating files:  39% (262/671)\rUpdating files:  40% (269/671)\rUpdating files:  41% (276/671)\rUpdating files:  42% (282/671)\rUpdating files:  43% (289/671)\rUpdating files:  44% (296/671)\rUpdating files:  45% (302/671)\rUpdating files:  46% (309/671)\rUpdating files:  47% (316/671)\rUpdating files:  48% (323/671)\rUpdating files:  49% (329/671)\rUpdating files:  50% (336/671)\rUpdating files:  51% (343/671)\rUpdating files:  52% (349/671)\rUpdating files:  53% (356/671)\rUpdating files:  54% (363/671)\rUpdating files:  55% (370/671)\rUpdating files:  56% (376/671)\rUpdating files:  56% (382/671)\rUpdating files:  57% (383/671)\rUpdating files:  58% (390/671)\rUpdating files:  59% (396/671)\rUpdating files:  60% (403/671)\rUpdating files:  61% (410/671)\rUpdating files:  62% (417/671)\rUpdating files:  63% (423/671)\rUpdating files:  64% (430/671)\rUpdating files:  65% (437/671)\rUpdating files:  66% (443/671)\rUpdating files:  67% (450/671)\rUpdating files:  68% (457/671)\rUpdating files:  69% (463/671)\rUpdating files:  70% (470/671)\rUpdating files:  71% (477/671)\rUpdating files:  72% (484/671)\rUpdating files:  73% (490/671)\rUpdating files:  74% (497/671)\rUpdating files:  75% (504/671)\rUpdating files:  75% (506/671)\rUpdating files:  76% (510/671)\rUpdating files:  77% (517/671)\rUpdating files:  78% (524/671)\rUpdating files:  79% (531/671)\rUpdating files:  80% (537/671)\rUpdating files:  81% (544/671)\rUpdating files:  82% (551/671)\rUpdating files:  83% (557/671)\rUpdating files:  84% (564/671)\rUpdating files:  85% (571/671)\rUpdating files:  86% (578/671)\rUpdating files:  87% (584/671)\rUpdating files:  88% (591/671)\rUpdating files:  89% (598/671)\rUpdating files:  90% (604/671)\rUpdating files:  91% (611/671)\rUpdating files:  92% (618/671)\rUpdating files:  93% (625/671)\rUpdating files:  94% (631/671)\rUpdating files:  95% (638/671)\rUpdating files:  96% (645/671)\rUpdating files:  97% (651/671)\rUpdating files:  98% (658/671)\rUpdating files:  99% (665/671)\rUpdating files: 100% (671/671)\rUpdating files: 100% (671/671), done.\n",
            "mv: cannot move 'hls4ml-tutorial/images' to './images': Directory not empty\n",
            "mv: cannot move 'hls4ml-tutorial/reports' to './reports': Directory not empty\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "git clone https://github.com/thesps/hls4ml-tutorial.git -b uzh2025\n",
        "mv hls4ml-tutorial/* .\n",
        "rm -r hls4ml-tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRQpQwQS8oKs"
      },
      "source": [
        "# Part 1: Quantizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "70B-TANa8oKs"
      },
      "outputs": [],
      "source": [
        "from qkeras.quantizers import quantized_bits, quantized_relu\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# set the random seed for reproducibility\n",
        "seed = 'uzh2025'\n",
        "seed = int.from_bytes(seed.encode('utf-8')) % 2**32\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTLpkrJC8oKs"
      },
      "source": [
        "## Quantize\n",
        "\n",
        "Let's first of all see what QKeras quantizers do by simply quantizing some values and plotting them. We first of all create a quantizer with 8 bits width and 4 bits integer (not including sign, in QKeras) with `q = quantized_bits(8,4)` and apply it to quantized the values in an array with `q(x)`.\n",
        "\n",
        "Try adding some more lines with different quantization applied. We created a uniformly sampled array of `x` - make sure that the spacing of `x` is more fine than the quantization you then use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjT45FQ48oKs",
        "outputId": "aed11b52-f431-4982-9773-9975b55d49f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class quantized_bits in module qkeras.quantizers:\n",
            "\n",
            "class quantized_bits(BaseQuantizer)\n",
            " |  quantized_bits(bits=8, integer=0, symmetric=0, keep_negative=True, alpha=None, use_stochastic_rounding=False, scale_axis=None, qnoise_factor=1.0, var_name=None, use_ste=True, use_variables=False)\n",
            " |  \n",
            " |  Quantizes the number to a number of bits.\n",
            " |  \n",
            " |  In general, we want to use a quantization function like:\n",
            " |  \n",
            " |  a = (pow(2,bits) - 1 - 0) / (max(x) - min(x))\n",
            " |  b = -min(x) * a\n",
            " |  \n",
            " |  in the equation:\n",
            " |  \n",
            " |  xq = a x + b\n",
            " |  \n",
            " |  This requires multiplication, which is undesirable. So, we\n",
            " |  enforce weights to be between -1 and 1 (max(x) = 1 and min(x) = -1),\n",
            " |  and separating the sign from the rest of the number as we make this function\n",
            " |  symmetric, thus resulting in the following approximation.\n",
            " |  \n",
            " |  1) max(x) = +1, min(x) = -1\n",
            " |  2) max(x) = -min(x)\n",
            " |  \n",
            " |  a = pow(2,bits-1)\n",
            " |  b = 0\n",
            " |  \n",
            " |  Finally, just remember that to represent the number with sign, the\n",
            " |  largest representation is -pow(2,bits) to pow(2, bits-1)\n",
            " |  \n",
            " |  Symmetric and keep_negative allow us to generate numbers that are symmetric\n",
            " |  (same number of negative and positive representations), and numbers that\n",
            " |  are positive.\n",
            " |  \n",
            " |  Note:\n",
            " |    the behavior of quantized_bits is different than Catapult HLS ac_fixed\n",
            " |    or Vivado HLS ap_fixed. For ac_fixed<word_length, integer_lenth, signed>,\n",
            " |    when signed = true, it is equavlent to\n",
            " |    quantized_bits(word_length, integer_length-1, keep_negative=True)\n",
            " |  \n",
            " |  Attributes:\n",
            " |    bits: number of bits to perform quantization.\n",
            " |    integer: number of bits to the left of the decimal point.\n",
            " |    symmetric: if true, we will have the same number of values for positive\n",
            " |      and negative numbers.\n",
            " |    alpha: a tensor or None, the scaling factor per channel.\n",
            " |      If None, the scaling factor is 1 for all channels.\n",
            " |    keep_negative: if true, we do not clip negative numbers.\n",
            " |    use_stochastic_rounding: if true, we perform stochastic rounding.\n",
            " |    scale_axis: which axis to calculate scale from\n",
            " |    qnoise_factor: float. a scalar from 0 to 1 that represents the level of\n",
            " |      quantization noise to add. This controls the amount of the quantization\n",
            " |      noise to add to the outputs by changing the weighted sum of\n",
            " |      (1 - qnoise_factor)*unquantized_x + qnoise_factor*quantized_x.\n",
            " |    var_name: String or None. A variable name shared between the tf.Variables\n",
            " |      created in the build function. If None, it is generated automatically.\n",
            " |    use_ste: Bool. Whether to use \"straight-through estimator\" (STE) method or\n",
            " |        not.\n",
            " |    use_variables: Bool. Whether to make the quantizer variables to be dynamic\n",
            " |      tf.Variables or not.\n",
            " |  \n",
            " |  Returns:\n",
            " |    Function that computes fixed-point quantization with bits.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      quantized_bits\n",
            " |      BaseQuantizer\n",
            " |      tensorflow.python.module.module.Module\n",
            " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
            " |      tensorflow.python.trackable.base.Trackable\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __call__(self, x)\n",
            " |      Computes fixedpoint quantization of x.\n",
            " |  \n",
            " |  __init__(self, bits=8, integer=0, symmetric=0, keep_negative=True, alpha=None, use_stochastic_rounding=False, scale_axis=None, qnoise_factor=1.0, var_name=None, use_ste=True, use_variables=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  __str__(self)\n",
            " |      Return str(self).\n",
            " |  \n",
            " |  get_config(self)\n",
            " |  \n",
            " |  max(self)\n",
            " |      Get maximum value that quantized_bits class can represent.\n",
            " |  \n",
            " |  min(self)\n",
            " |      Get minimum value that quantized_bits class can represent.\n",
            " |  \n",
            " |  range(self)\n",
            " |      Returns a list of all values that quantized_bits can represent\n",
            " |      ordered by their binary representation ascending.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  from_config(config)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from BaseQuantizer:\n",
            " |  \n",
            " |  build(self, var_name=None, use_variables=False)\n",
            " |  \n",
            " |  update_qnoise_factor(self, qnoise_factor)\n",
            " |      Update qnoise_factor.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from BaseQuantizer:\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      Sequence of trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  variables\n",
            " |      Sequence of variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  with_name_scope(method)\n",
            " |      Decorator to automatically enter the module name scope.\n",
            " |      \n",
            " |      >>> class MyModule(tf.Module):\n",
            " |      ...   @tf.Module.with_name_scope\n",
            " |      ...   def __call__(self, x):\n",
            " |      ...     if not hasattr(self, 'w'):\n",
            " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            " |      ...     return tf.matmul(x, self.w)\n",
            " |      \n",
            " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            " |      names included the module name:\n",
            " |      \n",
            " |      >>> mod = MyModule()\n",
            " |      >>> mod(tf.ones([1, 2]))\n",
            " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            " |      >>> mod.w\n",
            " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            " |      numpy=..., dtype=float32)>\n",
            " |      \n",
            " |      Args:\n",
            " |        method: The method to wrap.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The original method wrapped such that it enters the module's name scope.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  name\n",
            " |      Returns the name of this module as passed or determined in the ctor.\n",
            " |      \n",
            " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
            " |      parent module names.\n",
            " |  \n",
            " |  name_scope\n",
            " |      Returns a `tf.name_scope` instance for this class.\n",
            " |  \n",
            " |  submodules\n",
            " |      Sequence of all sub-modules.\n",
            " |      \n",
            " |      Submodules are modules which are properties of this module, or found as\n",
            " |      properties of modules which are properties of this module (and so on).\n",
            " |      \n",
            " |      >>> a = tf.Module()\n",
            " |      >>> b = tf.Module()\n",
            " |      >>> c = tf.Module()\n",
            " |      >>> a.b = b\n",
            " |      >>> b.c = c\n",
            " |      >>> list(a.submodules) == [b, c]\n",
            " |      True\n",
            " |      >>> list(b.submodules) == [c]\n",
            " |      True\n",
            " |      >>> list(c.submodules) == []\n",
            " |      True\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of all submodules.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from tensorflow.python.trackable.autotrackable.AutoTrackable:\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(quantized_bits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "CVPhyTcx8oKs",
        "outputId": "d916e693-15a5-4727-9886-a071081fc74e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x79d36af0c310>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = np.linspace(-4,4,4000)\n",
        "q = quantized_bits(8,0)\n",
        "r = quantized_bits(8,1)\n",
        "s = quantized_bits(8,3)\n",
        "t = quantized_bits(8,4)\n",
        "u = quantized_bits(8,5)\n",
        "\n",
        "x_quant_84 = q(x)\n",
        "w_quant_84 = r(x)\n",
        "z_quant_84 = s(x)\n",
        "y_quant_84 = t(x)\n",
        "b_quant_84 = u(x)\n",
        "\n",
        "\n",
        "plt.plot(x, x_quant_84, label='quantized_bits(8,0)')\n",
        "plt.legend()\n",
        "plt.plot(x, w_quant_84, label='quantized_bits(8,1)')\n",
        "plt.legend()\n",
        "plt.plot(x, z_quant_84, label='quantized_bits(8,3)')\n",
        "plt.legend()\n",
        "plt.plot(x, y_quant_84, label='quantized_bits(8,4)')\n",
        "plt.legend()\n",
        "plt.plot(x, b_quant_84, label='quantized_bits(8,5)')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPIraXQ38oKt",
        "outputId": "a6af478d-7249-4adf-da93-7e5630965970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 samples of x:\n",
            "[-4.        -3.9979995 -3.995999  -3.9939985 -3.991998  -3.9899975\n",
            " -3.987997  -3.9859965 -3.983996  -3.9819955]\n",
            "First 10 samples of q(x):\n",
            "[-4. -4. -4. -4. -4. -4. -4. -4. -4. -4.]\n"
          ]
        }
      ],
      "source": [
        "print(f'First 10 samples of x:\\n{x[:10]}')\n",
        "print(f'First 10 samples of q(x):\\n{x_quant_84[:10]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckD8QIhn8oKt"
      },
      "source": [
        "## Exercise - bit growth (sum)\n",
        "\n",
        "Now we want to test the ideas in the lecture in practice, by choosing the right number of bits for the result of some operations, starting with summation.\n",
        "\n",
        "Create a batch of vectors of random floating point number in a range, with 8 elements per vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NhJOj60K8oKt"
      },
      "outputs": [],
      "source": [
        "a = np.random.uniform(-16, 16, 1024).reshape(-1, 8)\n",
        "b = np.random.uniform(-16, 16, 1024).reshape(-1, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW1VXsTB8oKt",
        "outputId": "d5da535d-badc-480a-9fda-f9d2bd07a342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of a, shape of b: (128, 8), (128, 8)\n",
            "First 3 samples of a:\n",
            "[[-10.51059904  -9.37055411   3.08377872  11.29225425   7.76849976\n",
            "   -3.15968667  -1.75330912  14.93508634]\n",
            " [ 15.72840086   7.20569689 -13.36412856  -1.27035315   2.37630932\n",
            "  -11.92429693   2.164153    10.3545776 ]\n",
            " [  1.84651768  12.20920375   5.79288686 -14.2746262    0.65588212\n",
            "   10.92745605   7.41875887  10.97178638]]\n",
            "First 3 samples of b:\n",
            "[[-9.29121411e-03 -1.36403190e+01 -2.11219936e-01 -6.74035908e+00\n",
            "  -3.46878698e-01 -2.87967689e+00  1.07045414e+01 -1.59795553e+01]\n",
            " [ 1.17120843e+01 -5.09047133e+00  4.15134548e+00  1.71645195e+00\n",
            "   6.71156568e+00 -1.87522364e+00  5.11291513e+00  1.16785312e+00]\n",
            " [ 3.14732796e+00 -9.53965648e-01 -6.23783343e+00  1.29307723e+01\n",
            "  -1.59235524e+01  1.03219037e+01  4.01384873e+00 -1.31065997e+01]]\n"
          ]
        }
      ],
      "source": [
        "print(f'Shape of a, shape of b: {a.shape}, {b.shape}')\n",
        "print(f'First 3 samples of a:\\n{a[:3]}')\n",
        "print(f'First 3 samples of b:\\n{b[:3]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW0jc8S58oKt"
      },
      "source": [
        "## Quantize\n",
        "\n",
        "We will first quantize the random numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6mEeR_Pt8oKt"
      },
      "outputs": [],
      "source": [
        "q_i = quantized_bits(8,4) # quantizer for the inputs to the sum\n",
        "a_quant = q_i(a)\n",
        "b_quant = q_i(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seZSOnYr8oKt",
        "outputId": "7b7522a4-4a31-4db1-9cc6-7befcdc838f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of a_quant, shape of b_quant: (128, 8), (128, 8)\n",
            "First 3 samples of a_quant:\n",
            "[[-10.5    -9.375   3.125  11.25    7.75   -3.125  -1.75   14.875]\n",
            " [ 15.75    7.25  -13.375  -1.25    2.375 -11.875   2.125  10.375]\n",
            " [  1.875  12.25    5.75  -14.25    0.625  10.875   7.375  11.   ]]\n",
            "First 3 samples of b_quant:\n",
            "[[  0.    -13.625  -0.25   -6.75   -0.375  -2.875  10.75  -16.   ]\n",
            " [ 11.75   -5.125   4.125   1.75    6.75   -1.875   5.125   1.125]\n",
            " [  3.125  -1.     -6.25   12.875 -15.875  10.375   4.    -13.125]]\n"
          ]
        }
      ],
      "source": [
        "print(f'Shape of a_quant, shape of b_quant: {a_quant.shape}, {b_quant.shape}')\n",
        "print(f'First 3 samples of a_quant:\\n{a_quant[:3]}')\n",
        "print(f'First 3 samples of b_quant:\\n{b_quant[:3]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdsngvTm8oKt"
      },
      "source": [
        "### Sum\n",
        "\n",
        "Now we take the sum of the quantized vectors `c = a_quant + b_quant`. We then quantize that result with a new quantizer `c_quant = q_o_sum(c)`. Your task will be to define the quantization of the sum result such that `q_o_sum(c) == c`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "aeffLs398oKt"
      },
      "outputs": [],
      "source": [
        "# TODO: change the bits here\n",
        "q_o_sum = quantized_bits(9,5) # quantizer for the output of the sum, +1 for integer part, but also for total length\n",
        "c = a_quant + b_quant\n",
        "c_quant = q_o_sum(c) # quantize the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShPL4Lei8oKt",
        "outputId": "15aeae88-68f3-47d9-935a-ca951d770a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of c, shape of c_quant: (128, 8), (128, 8)\n",
            "First 3 samples of c:\n",
            "[[-10.5   -23.      2.875   4.5     7.375  -6.      9.     -1.125]\n",
            " [ 27.5     2.125  -9.25    0.5     9.125 -13.75    7.25   11.5  ]\n",
            " [  5.     11.25   -0.5    -1.375 -15.25   21.25   11.375  -2.125]]\n",
            "First 3 samples of c_quant:\n",
            "[[-10.5   -23.      2.875   4.5     7.375  -6.      9.     -1.125]\n",
            " [ 27.5     2.125  -9.25    0.5     9.125 -13.75    7.25   11.5  ]\n",
            " [  5.     11.25   -0.5    -1.375 -15.25   21.25   11.375  -2.125]]\n"
          ]
        }
      ],
      "source": [
        "print(f'Shape of c, shape of c_quant: {c.shape}, {c_quant.shape}')\n",
        "print(f'First 3 samples of c:\\n{c[:3]}')\n",
        "print(f'First 3 samples of c_quant:\\n{c_quant[:3]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk9wHAGS8oKt"
      },
      "source": [
        "### Task\n",
        "\n",
        "Use the right number of bits for `q_o_sum` such that the test below passes, finding the _smallest valid values_ for the width and number of integer bits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3DmU41IS8oKt"
      },
      "outputs": [],
      "source": [
        "np.testing.assert_array_equal(c, c_quant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifBKKUKs8oKt"
      },
      "source": [
        "## Inspect\n",
        "\n",
        "Visualize the differences below by plotting a histogram of the difference between `c` and `q(c)`. If we chose the right number of bits, the difference should be 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "mq5EYebW8oKt",
        "outputId": "edf5e4ff-6104-4ca8-b754-cbbf4f2cc8be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x79d36ac9ff50>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "bins = np.linspace(-16,16,4000)\n",
        "h, _ = np.histogram(c - c_quant, bins=bins)\n",
        "plt.step(bins[:-1], h, label='c - q(c)')\n",
        "plt.xlabel('c - q(c)')\n",
        "plt.ylabel('N')\n",
        "plt.semilogy()\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o26LAj468oKu"
      },
      "source": [
        "## Exercise - bit growth (dot product)\n",
        "\n",
        "Now we'll do a similar exercise, using the same batch of dimension 8 vectors, taking the dot product between the samples in `a` and those in `b`. Note we're not taking the dot product between the `(128,8)` arrays, but between the samples `(1,8) · (8,1)`, so we'll have 128 values.\n",
        "\n",
        "You need to choose the right quantizer for the result of the dot product such that the `d` and `d_quant` are equal. Use the rules you've learned for bitgrowth of multiplication and addition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "LZlPU7208oKu"
      },
      "outputs": [],
      "source": [
        "# TODO: change the bits here\n",
        "q_o_dot = quantized_bits(19,11) # quantizer for the output of the dot product\n",
        "d = np.sum(a_quant * b_quant, axis=-1) # take the dot between pairs of vectors\n",
        "d_quant = q_o_dot(d) # quantize the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrhzVaRm8oKu",
        "outputId": "4d08413b-1cdb-4ffa-eb98-6e796d593cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of d, shape of d_quant: (128,), (128,)\n",
            "First 10 samples of d:\n",
            "[-199.71875   151.40625  -237.76562  -319.79688   193.46875   -79.515625\n",
            " -137.95312  -255.34375  -166.40625    71.875   ]\n",
            "First 10 samples of d_quant:\n",
            "[-199.71875   151.40625  -237.76562  -319.79688   193.46875   -79.515625\n",
            " -137.95312  -255.34375  -166.40625    71.875   ]\n"
          ]
        }
      ],
      "source": [
        "print(f'Shape of d, shape of d_quant: {d.shape}, {d_quant.shape}')\n",
        "print(f'First 10 samples of d:\\n{d[:10]}')\n",
        "print(f'First 10 samples of d_quant:\\n{d_quant[:10]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "TQA6HUD28oKu"
      },
      "outputs": [],
      "source": [
        "np.testing.assert_array_equal(d, d_quant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzLasFBY8oKu"
      },
      "source": [
        "## Inspect\n",
        "\n",
        "Visualize the differences below by plotting a histogram of the difference between `d` and `q(d)`. If we chose the right number of bits, the difference should be 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "eEaRKHgn8oKu",
        "outputId": "da47b539-3eef-4186-d373-39a539075521"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x79d36a9b2c50>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "bins = np.linspace(-1000,1000,4000)\n",
        "h, _ = np.histogram(d - d_quant, bins=bins)\n",
        "plt.step(bins[:-1], h, label='d - q(d)')\n",
        "plt.xlabel('d - q(d)')\n",
        "plt.ylabel('N')\n",
        "plt.semilogy()\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xca5_c458oKu"
      },
      "source": [
        "# Part 2: Quantization Aware Training\n",
        "\n",
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "2L2aPwxK8oKu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5xaEqST8oKu"
      },
      "source": [
        "## Fetch the jet tagging dataset from Open ML\n",
        "\n",
        "**Note**: this takes about a minute to download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "MIpBha0_8oKu"
      },
      "outputs": [],
      "source": [
        "data = fetch_openml('hls4ml_lhc_jets_hlf')\n",
        "X, y = data['data'], data['target']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf2Fevd98oKu"
      },
      "source": [
        "### Let's print some information about the dataset\n",
        "Print the feature names and the dataset shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzdsTpuo8oKu",
        "outputId": "e8a2d6c2-b902-477c-91cd-4bf492936fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature names: ['zlogz', 'c1_b0_mmdt', 'c1_b1_mmdt', 'c1_b2_mmdt', 'c2_b1_mmdt', 'c2_b2_mmdt', 'd2_b1_mmdt', 'd2_b2_mmdt', 'd2_a1_b1_mmdt', 'd2_a1_b2_mmdt', 'm2_b1_mmdt', 'm2_b2_mmdt', 'n2_b1_mmdt', 'n2_b2_mmdt', 'mass_mmdt', 'multiplicity']\n",
            "\n",
            "X shape: (830000, 16)\n",
            "y shape: (830000,)\n",
            "\n",
            "First 10 samples, X:\n",
            "       zlogz  c1_b0_mmdt  c1_b1_mmdt  c1_b2_mmdt  c2_b1_mmdt  c2_b2_mmdt  \\\n",
            "0 -2.935125    0.383155    0.005126    0.000084    0.009070    0.000179   \n",
            "1 -1.927335    0.270699    0.001585    0.000011    0.003232    0.000029   \n",
            "2 -3.112147    0.458171    0.097914    0.028588    0.124278    0.038487   \n",
            "3 -2.666515    0.437068    0.049122    0.007978    0.047477    0.004802   \n",
            "4 -2.484843    0.428981    0.041786    0.006110    0.023066    0.001123   \n",
            "5 -2.513208    0.432403    0.033556    0.005395    0.034329    0.002248   \n",
            "6 -2.985767    0.461152    0.067243    0.016601    0.027135    0.001565   \n",
            "7 -2.961123    0.446868    0.008109    0.000198    0.011185    0.000253   \n",
            "8 -1.865473    0.316419    0.035149    0.007573    0.048492    0.005144   \n",
            "9 -3.934328    0.484746    0.081689    0.026640    0.106913    0.016657   \n",
            "\n",
            "   d2_b1_mmdt  d2_b2_mmdt  d2_a1_b1_mmdt  d2_a1_b2_mmdt  m2_b1_mmdt  \\\n",
            "0    1.769445    2.123898       1.769445       0.308185    0.135687   \n",
            "1    2.038834    2.563099       2.038834       0.211886    0.063729   \n",
            "2    1.269254    1.346238       1.269254       0.246488    0.115636   \n",
            "3    0.966505    0.601864       0.966505       0.160756    0.082196   \n",
            "4    0.552002    0.183821       0.552002       0.084338    0.048006   \n",
            "5    1.023059    0.416652       1.023059       0.097535    0.046242   \n",
            "6    0.403539    0.094279       0.403539       0.057364    0.030692   \n",
            "7    1.379300    1.280585       1.379300       0.264133    0.133699   \n",
            "8    1.379590    0.679237       1.379590       0.090910    0.033383   \n",
            "9    1.308779    0.625250       1.308779       0.164078    0.082619   \n",
            "\n",
            "   m2_b2_mmdt  n2_b1_mmdt  n2_b2_mmdt   mass_mmdt  multiplicity  \n",
            "0    0.083278    0.412136    0.299058    8.926882          75.0  \n",
            "1    0.036310    0.310217    0.226661    3.886512          31.0  \n",
            "2    0.079094    0.357559    0.289220  162.144669          61.0  \n",
            "3    0.033311    0.238871    0.094516   91.258934          39.0  \n",
            "4    0.014450    0.141906    0.036665   79.725777          35.0  \n",
            "5    0.010088    0.182382    0.046085   76.540482          33.0  \n",
            "6    0.004315    0.100868    0.015029  140.221115          45.0  \n",
            "7    0.068612    0.351283    0.193276   19.602045          53.0  \n",
            "8    0.010312    0.187562    0.060151   86.289276          36.0  \n",
            "9    0.025696    0.273431    0.091603  170.655014         103.0  \n",
            "\n",
            "First 10 samples, y:\n",
            " 0    g\n",
            "1    w\n",
            "2    t\n",
            "3    z\n",
            "4    w\n",
            "5    w\n",
            "6    t\n",
            "7    g\n",
            "8    z\n",
            "9    g\n",
            "Name: class, dtype: category\n",
            "Categories (5, object): ['g', 'q', 't', 'w', 'z']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Feature names: {data['feature_names']}\\n\")\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\\n\")\n",
        "print(f\"First 10 samples, X:\\n {X[:10]}\\n\")\n",
        "print(f\"First 10 samples, y:\\n {y[:10]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS1YUHUS8oKu"
      },
      "source": [
        "As you saw above, the `y` target is an array of strings of the jet flavour, e.g. \\['g', 'w',...\\] etc.\n",
        "We need to make this a \"One Hot\" encoding for the training.\n",
        "Then, split the dataset into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhdCktMw8oKu",
        "outputId": "aae36fe5-1137-45a0-cc33-407ae4dc4780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y = to_categorical(y, 5)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(y[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "u0R5d1cl8oKu"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_val = scaler.fit_transform(X_train_val)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HgSTyX08oKu"
      },
      "source": [
        "Save the preprocessed and train-test-split arrays to files so that we can skip the steps above next time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "-g0PCSoF8oKu"
      },
      "outputs": [],
      "source": [
        "np.save('X_train_val.npy', X_train_val)\n",
        "np.save('X_test.npy', X_test)\n",
        "np.save('y_train_val.npy', y_train_val)\n",
        "np.save('y_test.npy', y_test)\n",
        "np.save('classes.npy', le.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyhbLZAW8oKy"
      },
      "source": [
        "## Now construct a model\n",
        "We'll use 3 hidden layers with 64, then 32, then 32 neurons. Each layer will use `relu` activation.\n",
        "Add an output layer with 5 neurons (one for each class), then finish with Softmax activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etz3r1lD8oKy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from callbacks import all_callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixHmfiS_8oKy"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(16,), name='fc1', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "model.add(Activation(activation='relu', name='relu1'))\n",
        "model.add(Dense(32, name='fc2', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "model.add(Activation(activation='relu', name='relu2'))\n",
        "model.add(Dense(32, name='fc3', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "model.add(Activation(activation='relu', name='relu3'))\n",
        "model.add(Dense(5, name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "model.add(Activation(activation='softmax', name='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-6LUPKU8oKy"
      },
      "source": [
        "## Train the model\n",
        "We'll use Adam optimizer with categorical crossentropy loss.\n",
        "The callbacks will decay the learning rate and save the model into a directory 'model_1'\n",
        "The model isn't very complex, so this should just take a few minutes even on the CPU.\n",
        "If you've restarted the notebook kernel after training once, set `train = False` to load the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5HRr9xO8oKy"
      },
      "outputs": [],
      "source": [
        "train = True\n",
        "if train:\n",
        "    adam = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
        "    callbacks = all_callbacks(\n",
        "        stop_patience=1000,\n",
        "        lr_factor=0.5,\n",
        "        lr_patience=10,\n",
        "        lr_epsilon=0.000001,\n",
        "        lr_cooldown=2,\n",
        "        lr_minimum=0.0000001,\n",
        "        outputDir='model_1',\n",
        "    )\n",
        "    model.fit(\n",
        "        X_train_val,\n",
        "        y_train_val,\n",
        "        batch_size=1024,\n",
        "        epochs=30,\n",
        "        validation_split=0.25,\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks.callbacks,\n",
        "    )\n",
        "else:\n",
        "    from tensorflow.keras.models import load_model\n",
        "\n",
        "    model = load_model('model_1/KERAS_check_best_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhJKbiXm8oKy"
      },
      "source": [
        "## Check performance\n",
        "Check the accuracy and make a ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXELDUfd8oKy"
      },
      "outputs": [],
      "source": [
        "import plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_keras = model.predict(X_test)\n",
        "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
        "plt.figure(figsize=(9, 9))\n",
        "_ = plotting.makeRoc(y_test, y_keras, le.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SsEt0cZ8oKy"
      },
      "source": [
        "# Quantization Aware Training\n",
        "\n",
        "Now we train a new model using Quantization Aware Training via `QKeras`.\n",
        "\n",
        "We replace layers like `Dense` and `Activation` with `QDense` and `QActivation`, and specifiy quantizers to use for the weights, biases and activations.\n",
        "\n",
        "Notice that the model is still a `Keras` model, and the last layer is a regular `Keras` `Softmax` layer. In general you can mix-and-match normal `Keras` layers with `QKeras` ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_PH3Dgz8oKy"
      },
      "outputs": [],
      "source": [
        "from qkeras.qlayers import QDense, QActivation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhrLYsK98oKy"
      },
      "outputs": [],
      "source": [
        "qmodel = Sequential()\n",
        "qmodel.add(\n",
        "    QDense(\n",
        "        64,\n",
        "        input_shape=(16,),\n",
        "        name='fc1',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "qmodel.add(QActivation(activation=quantized_relu(6), name='relu1'))\n",
        "qmodel.add(\n",
        "    QDense(\n",
        "        32,\n",
        "        name='fc2',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "qmodel.add(QActivation(activation=quantized_relu(6), name='relu2'))\n",
        "qmodel.add(\n",
        "    QDense(\n",
        "        32,\n",
        "        name='fc3',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "qmodel.add(QActivation(activation=quantized_relu(6), name='relu3'))\n",
        "qmodel.add(\n",
        "    QDense(\n",
        "        5,\n",
        "        name='output',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "qmodel.add(Activation(activation='softmax', name='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7IffPfH8oKy"
      },
      "outputs": [],
      "source": [
        "train = True\n",
        "if train:\n",
        "    adam = Adam(lr=0.0001)\n",
        "    qmodel.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
        "    callbacks = all_callbacks(\n",
        "        stop_patience=1000,\n",
        "        lr_factor=0.5,\n",
        "        lr_patience=10,\n",
        "        lr_epsilon=0.000001,\n",
        "        lr_cooldown=2,\n",
        "        lr_minimum=0.0000001,\n",
        "        outputDir='qmodel_1',\n",
        "    )\n",
        "    qmodel.fit(\n",
        "        X_train_val,\n",
        "        y_train_val,\n",
        "        batch_size=1024,\n",
        "        epochs=30,\n",
        "        validation_split=0.25,\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks.callbacks,\n",
        "    )\n",
        "    qmodel.save('qmodel_1/KERAS_check_best_model.h5')\n",
        "else:\n",
        "    from tensorflow.keras.models import load_model\n",
        "    from qkeras.utils import _add_supported_quantized_objects\n",
        "\n",
        "    co = {}\n",
        "    _add_supported_quantized_objects(co)\n",
        "    qmodel = load_model('qmodel_1/KERAS_check_best_model.h5', custom_objects=co)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1ndbPHS8oKy"
      },
      "source": [
        "## Compare\n",
        "\n",
        "Plot the ROC curve of the QKeras model alongside the Keras model we trained earlier, and print the accuracy of both. If we chose appropriate quantization, they should perform quite similarly 🤞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "146fsJ3l8oKz"
      },
      "outputs": [],
      "source": [
        "y_qkeras = qmodel.predict(X_test)\n",
        "\n",
        "print(\"Accuracy Keras:  {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
        "print(\"Accuracy QKeras: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras, axis=1))))\n",
        "\n",
        "plt.figure(figsize=(9, 9))\n",
        "_ = plotting.makeRoc(y_test, y_keras, le.classes_)\n",
        "plt.gca().set_prop_cycle(None)  # reset the colors\n",
        "_ = plotting.makeRoc(y_test, y_qkeras, le.classes_, linestyle='--')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdehlE3c8oKz"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Try changing the quantization of the weights, biases, and activations and retrain the QKeras model above. See how much you can reduce the bitwidths while maintaining an accuracy above 75%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE_ykPhb8oKz"
      },
      "source": [
        "# Convert to FPGA code using `hls4ml`\n",
        "\n",
        "Now we use `hls4ml` to transpile our trained Neural Network model into High Level Synthesis code that can by synthesized for FPGA. We first of all produce a configuration that details all of the settings to use in the FPGA code generation, including quantization and other parameters. When using QKeras, the quantization settings can be extracted from the `qmodel` that we provide.\n",
        "\n",
        "After producing and editing the configuration, we `convert` the model into an `hls4ml` model object. This captures all of the parameters of the neural network, and provides an interface to produce FPGA code products for the model. We start by writing the project files, which you will find under `qmodel_q/hls4ml_prj`. This includes the C++ (HLS) description of the model we provided, including the architecture, its weights and bias values, the quantization settings, and the optimized inference functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjrTlStM8oKz"
      },
      "outputs": [],
      "source": [
        "import hls4ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMDfS5b48oKz"
      },
      "outputs": [],
      "source": [
        "config = hls4ml.utils.config_from_keras_model(qmodel, granularity='name', backend='Vitis', default_precision='fixed<16,7>')\n",
        "config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
        "config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
        "config['LayerName']['softmax']['Implementation'] = 'latency'\n",
        "print(\"-----------------------------------\")\n",
        "plotting.print_dict(config)\n",
        "print(\"-----------------------------------\")\n",
        "hls_model = hls4ml.converters.convert_from_keras_model(\n",
        "    qmodel, hls_config=config, backend='Vitis', output_dir='qmodel_1/hls4ml_prj', part='xcu250-figd2104-2L-e'\n",
        ")\n",
        "hls_model.write()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVadIpjJ8oKz"
      },
      "source": [
        "## Validate\n",
        "\n",
        "The FPGA design flow is time consuming, and working with FPGA hardware is not trivial. It's always good practice to check on our CPU that the FPGA design is correct before we go further. Since our Neural Network has been converted to C++ code (HLS), we can compile and run it on the CPU as well. `hls4ml` provides bindings and scripts to compile the C++ code and interact with it from Python. Here we compile the code and make an inference (on CPU) on our `X_test` data. This emulation produces bit-accurate results to what we would see on the FPGA device, given the same inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oTptP0I8oKz"
      },
      "outputs": [],
      "source": [
        "hls_model.compile()\n",
        "y_hls4ml = hls_model.predict(np.ascontiguousarray(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjmsw3Df8oKz"
      },
      "source": [
        "## Compare\n",
        "\n",
        "Let's again produce the ROC curve, now with the original Keras model, the quantized QKeras model, and the hls4ml emulation of the QKeras model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iH01XLMt8oKz"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy Keras:  {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
        "print(\"Accuracy QKeras: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras, axis=1))))\n",
        "print(\"Accuracy hls4ml: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls4ml, axis=1))))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(9, 9))\n",
        "_ = plotting.makeRoc(y_test, y_keras, [c + ' Keras' for c in le.classes_])\n",
        "plt.gca().set_prop_cycle(None)  # reset the colors\n",
        "_ = plotting.makeRoc(y_test, y_qkeras, [c + ' QKeras' for c in le.classes_], linestyle='--')\n",
        "plt.gca().set_prop_cycle(None)  # reset the colors\n",
        "_ = plotting.makeRoc(y_test, y_hls4ml, [c + ' hls4ml' for c in le.classes_], linestyle=':')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkcsESB18oKz"
      },
      "source": [
        "# Synthesize\n",
        "\n",
        "Everything we've done so far has taken place on the CPU. In order to go further with the FPGA we need to _synthesize_ the HLS C++ code into a lower level: _Harwdare Description Language_. This process uses software from the FPGA vendor, in this case AMD Xilinx, called `Vitis HLS`.\n",
        "\n",
        "This might not be available in the environment you're using, so if it's available then the cell below will run this step, otherwise this step will pick up a report that's provided. The report output summarises estimates of the latency and resource usage of the neural network. Look at the absolute inference latency, and the percentage total resource usage of each resource type.\n",
        "\n",
        "This report is a so called \"Out of Context\" report - meaning that the Neural Network is not interfaced to any other component. In a real system the Neural Network needs to be connected to the outside world somehow to receive its inputs and do something with its outputs. In Level 1 Trigger hardware, this can be achieved with extremely low latency and high throughput, but in other edge hardware that might not be the case. This ultra low latency inference can only be obtained with a correspondingly high performance I/O."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzyaHEFT8oKz"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "if shutil.which('vitis_hls') is not None:\n",
        "    # Vitis HLS is available, run csynthesis\n",
        "    hls_model.build()\n",
        "    qreport = 'qmodel_1/hls4ml_prj'\n",
        "else:\n",
        "    # use an already made report\n",
        "    qreport = 'reports/qmodel_1/hls4ml_prj'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV2my5u38oKz"
      },
      "outputs": [],
      "source": [
        "hls4ml.report.read_vivado_report(qreport)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP4mXzx28oKz"
      },
      "source": [
        "## Compare\n",
        "\n",
        "We can also synthesize the first, non-quantized Keras model that we trained. We use a method called \"Post Training Quantization\" where the floating point weights, biases, and activations are mapped onto fixed point representations after the model is trained. This usually comes with some performace degradation if the bitwidths are not wide enough, so `hls4ml` defaults to using 16 bits for everything. Compare this reports to see how much more efficient Quantization Aware Training can be!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlcK_zPU8oKz"
      },
      "outputs": [],
      "source": [
        "if shutil.which('vitis_hls') is not None:\n",
        "    fconfig = hls4ml.utils.config_from_keras_model(model, granularity='model', backend='Vitis')\n",
        "    print(\"-----------------------------------\")\n",
        "    print(\"Configuration\")\n",
        "    plotting.print_dict(fconfig)\n",
        "    print(\"-----------------------------------\")\n",
        "    hls_fmodel = hls4ml.converters.convert_from_keras_model(\n",
        "        model, hls_config=fconfig, backend='Vitis', output_dir='model_1/hls4ml_prj', part='xcu250-figd2104-2L-e'\n",
        "    )\n",
        "    hls_fmodel.build()\n",
        "    freport = 'model_1/hls4ml_prj'\n",
        "else:\n",
        "    freport = 'reports/model_1/hls4ml_prj'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrHE1Hfg8oKz"
      },
      "outputs": [],
      "source": [
        "hls4ml.report.read_vivado_report(freport)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqgERce18oKz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
